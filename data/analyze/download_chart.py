from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

print("import start")
import os
import time
import pickle
import shutil
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager
print("import end")

class DownloadChart:

    def __init__(self):
        base_dir = Path(__file__).parent
        self.COOKIES_PATH = str(base_dir / "spotify_cookies.pkl")
        self.DOWNLOAD_DIR = "/Users/pdh/Desktop/Project/spotify2/data/downloaded_spotify_files"
        self.options = webdriver.ChromeOptions()

    def save_cookies_after_manual_login(self):
        self.options.add_argument(f"--user-data-dir={os.path.expanduser('~')}/.spotify_profile")

        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=self.options)
        driver.get("https://charts.spotify.com/")
        print("ìˆ˜ë™ìœ¼ë¡œ ë¡œê·¸ì¸í•˜ì„¸ìš”.")
        input("ë¡œê·¸ì¸ ì™„ë£Œ í›„ Enter í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        driver.refresh()
        with open(self.COOKIES_PATH, "wb") as f:
            pickle.dump(driver.get_cookies(), f)
        print("ì¿ í‚¤ ì €ì¥ ì™„ë£Œ")
        driver.quit()

    async def create_driver_with_cookies(self) -> webdriver.Chrome:
        options = webdriver.ChromeOptions()
        # options.add_argument("--headless")
        prefs = {"download.default_directory": self.DOWNLOAD_DIR}
        options.add_experimental_option("prefs", prefs)
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
        driver.get("https://charts.spotify.com/")
        if not Path(self.COOKIES_PATH).exists():
            raise FileNotFoundError("ì¿ í‚¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        with open(self.COOKIES_PATH, "rb") as f:
            cookies = pickle.load(f)
            for cookie in cookies:
                try:
                    driver.add_cookie(cookie)
                except Exception:
                    pass
        driver.get("https://charts.spotify.com/")
        return driver

    def close_cookie_banner(self, driver):
        try:
            WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.ID, "onetrust-accept-btn-handler"))
            ).click()
            print("âœ… ì¿ í‚¤ ë°°ë„ˆ ë‹«ìŒ")
        except Exception as e:
            print("âŒ ì¿ í‚¤ ë°°ë„ˆ ë‹«ê¸° ì‹¤íŒ¨:", e)

    async def wait_for_download_and_rename(self, download_dir, expected_partial_name, new_filename, timeout=30):
        start_time = time.time()
        while time.time() - start_time < timeout:
            for fname in os.listdir(download_dir):
                if fname.startswith(expected_partial_name) and fname.endswith(".csv"):
                    full_path = os.path.join(download_dir, fname)
                    dst_path = os.path.join(download_dir, new_filename)
                    shutil.move(full_path, dst_path)
                    print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {dst_path}")
                    return dst_path
            time.sleep(1)
        raise TimeoutError("âŒ ë‹¤ìš´ë¡œë“œëœ CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    async def fetch_korea_chart_by_date(self, driver, target_date: str, chart_type="daily"):
        url = f"https://charts.spotify.com/charts/view/regional-kr-{chart_type}/{target_date}"
        driver.get(url)
        time.sleep(3)
        self.close_cookie_banner(driver)
        try:
            btn = driver.find_element(By.XPATH, '//*[@id="__next"]/div/div[3]/div/div/div[2]/span/span/button')
            btn.click()
            print(f"[{target_date}] ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")
        except Exception as e:
            print(f"[{target_date}] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")

    async def crawl_one(self, date_str: str, chart_type="weekly"):
        """ì§€ì •ëœ ë‚ ì§œ í•˜ë£¨ë§Œ ë‹¤ìš´ë¡œë“œ (ì´ë¯¸ ìˆìœ¼ë©´ ìƒëµ)"""
        print(date_str)
        new_filename = f"spotify_kr_{chart_type}_{date_str}.csv"
        file_path = os.path.join(self.DOWNLOAD_DIR, new_filename)

        if os.path.exists(file_path):
            print(f"ğŸ“ ì´ë¯¸ ì¡´ì¬í•¨, ë‹¤ìš´ë¡œë“œ ìƒëµ: {file_path}")
            return

        driver = await self.create_driver_with_cookies()
        await self.fetch_korea_chart_by_date(driver, date_str, chart_type=chart_type)
        print("ë‹¤ìš´ë¡œë“œ ëŒ€ê¸° ì¤‘...")

        try:
            expected_name = f"regional-kr-{chart_type}-{date_str}"
            await self.wait_for_download_and_rename(self.DOWNLOAD_DIR, expected_name, new_filename)
        except Exception as e:
            print(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        time.sleep(3)
        driver.quit()

download_chart = DownloadChart()

if __name__ == "__main__":
    print("ğŸš€ Spotify KR Chart Downloader ì‹œì‘")
    download_chart = DownloadChart()

    # download_chart.save_cookies_after_manual_login()  # ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰
    import asyncio
    asyncio.run(download_chart.crawl_one(date_str="2025-05-15"))
    #
    # with open("spotify_cookies.pkl", "rb") as f:
    #     cookies = pickle.load(f)
    #     print(cookies)  # ì´ê²Œ Noneì´ë¼ë©´ ë¬¸ì œ ë°œìƒ ì§€ì  í™•ì •
    